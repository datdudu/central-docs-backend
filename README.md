# Central Docs Backend

API RESTful para upload, ingest√£o, consulta e hist√≥rico de datasets (CSV/PDF), desenvolvida em Node.js, Express, Prisma e PostgreSQL.

## üöÄ Funcionalidades

- Registro e autentica√ß√£o de usu√°rios (JWT)
- Upload de arquivos `.csv` e `.pdf`
- Ingest√£o autom√°tica de dados de CSV para o banco
- Consulta de datasets e registros
- Busca por campo/valor nos registros
- Registro e hist√≥rico de queries simuladas
- **Integra√ß√£o com IA (Hugging Face) para gera√ß√£o autom√°tica de respostas**
- Documenta√ß√£o Swagger
- Testes automatizados
- Docker e Docker Compose

---

## üõ†Ô∏è Tecnologias

- Node.js + Express
- PostgreSQL + Prisma ORM
- JWT para autentica√ß√£o
- Multer para upload de arquivos
- Docker e Docker Compose
- Swagger para documenta√ß√£o
- Jest + Supertest para testes
- **Integra√ß√£o com Hugging Face Inference API**

---

## Fluxograma do Backend

```mermaid
flowchart TD
    A[Usu√°rio] --> B[Registro/Login]
    B --> C[Upload de Dataset]
    C --> D[Ingest√£o de Dados]
    D --> E[Consulta/Listagem]
    E --> F[Registro de Query]
    F --> G[Hist√≥rico de Queries]
```

---

## ‚öôÔ∏è Como rodar o projeto

### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/seu-usuario/central-docs-backend.git
cd central-docs-backend
```

### 2. Configure o ambiente

Crie um arquivo `.env` na raiz com:

```
DATABASE_URL=postgres://postgres:admin@localhost:5432/centraldocs
JWT_SECRET=12345678
PORT=3000
HF_API_TOKEN=seu_token_huggingface
```

> **Importante:** Para usar a integra√ß√£o com IA, gere um token gratuito em https://huggingface.co/settings/tokens e coloque em `HF_API_TOKEN`.

### 3. Instale as depend√™ncias

```bash
npm install
```

### 4. Rode tudo com Docker

```bash
docker compose up --build
```

---

## üß™ Rodando os testes

```bash
npm test
```

---

## üìö Documenta√ß√£o da API

Acesse a documenta√ß√£o Swagger em:
[http://localhost:3000/api-docs](http://localhost:3000/api-docs)

---

## üì¶ Exemplos de requisi√ß√µes

### Registro

```http
POST /auth/register
Content-Type: application/json

{
  "nome": "Jo√£o",
  "email": "joao@email.com",
  "senha": "123456"
}
```

### Login

```http
POST /auth/login
Content-Type: application/json

{
  "email": "joao@email.com",
  "senha": "123456"
}
```

### Upload de dataset

```http
POST /datasets/upload
Authorization: Bearer <token>
Content-Type: multipart/form-data

file: arquivo.csv
```

### Listar datasets

```http
GET /datasets
Authorization: Bearer <token>
```

### Listar registros de um dataset

```http
GET /datasets/{id}/records
Authorization: Bearer <token>
```

### Buscar registros por campo/valor

```http
GET /datasets/{id}/records/search?campo=nome&valor=Jo√£o
Authorization: Bearer <token>
```

### **Registrar query com resposta autom√°tica da IA**

```http
POST /queries
Authorization: Bearer <token>
Content-Type: application/json

{
  "pergunta": "Onde fica a Torre Eiffel?",
  "datasetId": 1
}
```
> O campo `datasetId` √© opcional. Se informado, a IA usar√° os dados do dataset como contexto para gerar a resposta.

**Resposta esperada:**
```json
{
  "id": 1,
  "usuario_id": 123,
  "pergunta": "Onde fica a Torre Eiffel?",
  "resposta": "A Torre Eiffel fica em Paris, Fran√ßa.",
  "criado_em": "2025-07-20T..."
}
```

### Listar queries do usu√°rio

```http
GET /queries
Authorization: Bearer <token>
```

---

## üìù Observa√ß√µes

- Os arquivos enviados ficam na pasta `/uploads`.
- Apenas arquivos `.csv` e `.pdf` s√£o aceitos.
- O campo `dados_json` da tabela `Record` armazena cada linha do CSV como um objeto JSON.
- **A integra√ß√£o com IA utiliza o modelo `deepset/roberta-base-squad2` da Hugging Face para responder perguntas com base no contexto do dataset.**

---

## üê≥ Docker

O projeto j√° est√° pronto para rodar com Docker e Docker Compose.
Basta rodar:

```bash
docker compose up --build
```

---

## üë§ Autor

Carlos Eduardo Carvalho Cardoso |
[LinkedIn](https://www.linkedin.com/in/c-eduardocarvalho/) |
[GitHub](https://github.com/datdudu)

---